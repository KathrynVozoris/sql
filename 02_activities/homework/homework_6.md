# Homework 6: Reflecton

- Due on Saturday, September 21 at 11:59pm
- Weight: 8% of total grade

<br>

**Write**: Reflect on your previous work and how you would adjust to include ethics and inequity components. Total length should be a few paragraphs, no more than one page.

In our discussion we considered different aspects of data ethics – privacy, equity and inclusion. Equity in data is an ongoing issue that constantly needs to be considered in our data management. Our methods need to take into account changing social norms, and strive to achieve equity and inclusion. Unfortunately, those most negatively affected tend to be communities that are traditionally marginalized and disenfranchised.  Attempting to put all of society into boxed categories is problematic. To counter these issues, we must think more broadly, and anticipate societal changes that may occur in the future. We also need to act quickly when issues arise, e.g. when there are perhaps just a few people that do not fit into the categories we have created.  We need to consider if our data categories need to be adjusted, and ask who is being left out? 

The discussion around the policy in Pakistan where two birth parents are required to be listed to obtain government ID”s was shocking. The disenfranchisement that entailed from this could have easily been anticipated, as children being born to  single unmarried parents is not new. Hence, it is clear that the bias in this data creation process had no safeguards in place.  This raises the  question of the need  for checks to be in place ensuring such an event does not occur. How does an entity create sufficient oversight, for there to be no intentional or unintentional bias in the data design process? This is particularly important in government run programs but could easily be as important in large private companies that have the ability to affect large portions of the population. Hence, there need to be government policies in place that ensure fairness and oversight where possible.  Unfortunately though, the bias is at times built into government policies and platforms.

It was interesting to hear the personal stories and difficulties that students in the cohort had in coming to Canada, again having issues with their names. In particular one person's brothers' name was listed incorrectly on a document and he has since had difficulties due to this discrepency. Additionaly some told of people with only one name, having their name listed twice as 'first name' and 'last name'. This was discouraging to note that even in more progressive societies their are still issues with incorporating cultural differences in naming traditions into data managment. 

The coding involved in data processes can be technically complex. So some decisions cannot always be easily considered by non-technical experts. Therefore, it is important that data scientists undergo anti-bias training to increase awareness and encourage broad thinking. When there are sensitive issues involved, decisions around data design need to be reviewed and approved by a diverse group of people and not a single individual. The antidote Thomas mentioned about gender being stored as a boolean -- male as True and female as False--was a good example of where had there been multiple people included in this choice, it may have been avoided.

In discussing Vicki Boykis’ article, we considered the issues of workers rights, and built in bias in the creation of AI models.  This is a complex issue as the amount of data being collected is so large. The data models could include more checks and balances to counter the bias of those creating feedback for the models. As far as the workers rights, this is a complicated issue as it involves companies hiring workers internationally. This is a crisis in many industries, which have also not found solutions. For example, the fashion industry has considered safeguards for decades but workers in developing countries continue to be exploited. 

 

